---
library_name: transformers
license: apache-2.0
base_model: bert-base-uncased
tags:
- generated_from_trainer
datasets:
- ibm-research/MedMentions-ZS
model-index:
- name: checkpoints
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# checkpoints

This model is a fine-tuned version of [bert-base-uncased](https://huggingface.co/bert-base-uncased) on the ibm-research/MedMentions-ZS dataset.
It achieves the following results on the evaluation set:
- Loss: 0.6765
- T005 Precision: 0.6667
- T005 Recall: 0.48
- T005 F1: 0.5581
- T005 Number: 25
- T007 Precision: 0.6486
- T007 Recall: 0.5333
- T007 F1: 0.5854
- T007 Number: 45
- T017 Precision: 0.6560
- T017 Recall: 0.6991
- T017 F1: 0.6769
- T017 Number: 1233
- T022 Precision: 0.6
- T022 Recall: 0.3333
- T022 F1: 0.4286
- T022 Number: 9
- T031 Precision: 0.6111
- T031 Recall: 0.5
- T031 F1: 0.55
- T031 Number: 22
- T033 Precision: 0.5205
- T033 Recall: 0.5388
- T033 F1: 0.5295
- T033 Number: 991
- T037 Precision: 0.575
- T037 Recall: 0.5227
- T037 F1: 0.5476
- T037 Number: 44
- T038 Precision: 0.6850
- T038 Recall: 0.7095
- T038 F1: 0.6970
- T038 Number: 2568
- T058 Precision: 0.5744
- T058 Recall: 0.6409
- T058 F1: 0.6058
- T058 Number: 1487
- T062 Precision: 0.5197
- T062 Recall: 0.5725
- T062 F1: 0.5448
- T062 Number: 552
- T074 Precision: 0.5785
- T074 Recall: 0.6087
- T074 F1: 0.5932
- T074 Number: 115
- T082 Precision: 0.588
- T082 Recall: 0.5943
- T082 F1: 0.5912
- T082 Number: 742
- T091 Precision: 0.4667
- T091 Recall: 0.35
- T091 F1: 0.4
- T091 Number: 20
- T092 Precision: 0.2
- T092 Recall: 0.1892
- T092 F1: 0.1944
- T092 Number: 37
- T097 Precision: 0.1429
- T097 Recall: 0.2
- T097 F1: 0.1667
- T097 Number: 15
- T098 Precision: 0.6986
- T098 Recall: 0.7265
- T098 F1: 0.7123
- T098 Number: 351
- T103 Precision: 0.7322
- T103 Recall: 0.7590
- T103 F1: 0.7454
- T103 Number: 2187
- T168 Precision: 0.4815
- T168 Recall: 0.4643
- T168 F1: 0.4727
- T168 Number: 28
- T170 Precision: 0.5545
- T170 Recall: 0.5786
- T170 F1: 0.5663
- T170 Number: 598
- T201 Precision: 0.4
- T201 Recall: 0.3
- T201 F1: 0.3429
- T201 Number: 40
- T204 Precision: 0.7470
- T204 Recall: 0.7782
- T204 F1: 0.7623
- T204 Number: 478
- Overall Precision: 0.6382
- Overall Recall: 0.6685
- Overall F1: 0.6530
- Overall Accuracy: 0.8851

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 5e-05
- train_batch_size: 8
- eval_batch_size: 8
- seed: 42
- gradient_accumulation_steps: 2
- total_train_batch_size: 16
- optimizer: Use OptimizerNames.ADAMW_TORCH with betas=(0.9,0.999) and epsilon=1e-08 and optimizer_args=No additional optimizer arguments
- lr_scheduler_type: linear
- num_epochs: 10.0
- mixed_precision_training: Native AMP

### Training results

| Training Loss | Epoch | Step  | Validation Loss | T005 Precision | T005 Recall | T005 F1 | T005 Number | T007 Precision | T007 Recall | T007 F1 | T007 Number | T017 Precision | T017 Recall | T017 F1 | T017 Number | T022 Precision | T022 Recall | T022 F1 | T022 Number | T031 Precision | T031 Recall | T031 F1 | T031 Number | T033 Precision | T033 Recall | T033 F1 | T033 Number | T037 Precision | T037 Recall | T037 F1 | T037 Number | T038 Precision | T038 Recall | T038 F1 | T038 Number | T058 Precision | T058 Recall | T058 F1 | T058 Number | T062 Precision | T062 Recall | T062 F1 | T062 Number | T074 Precision | T074 Recall | T074 F1 | T074 Number | T082 Precision | T082 Recall | T082 F1 | T082 Number | T091 Precision | T091 Recall | T091 F1 | T091 Number | T092 Precision | T092 Recall | T092 F1 | T092 Number | T097 Precision | T097 Recall | T097 F1 | T097 Number | T098 Precision | T098 Recall | T098 F1 | T098 Number | T103 Precision | T103 Recall | T103 F1 | T103 Number | T168 Precision | T168 Recall | T168 F1 | T168 Number | T170 Precision | T170 Recall | T170 F1 | T170 Number | T201 Precision | T201 Recall | T201 F1 | T201 Number | T204 Precision | T204 Recall | T204 F1 | T204 Number | Overall Precision | Overall Recall | Overall F1 | Overall Accuracy |
|:-------------:|:-----:|:-----:|:---------------:|:--------------:|:-----------:|:-------:|:-----------:|:--------------:|:-----------:|:-------:|:-----------:|:--------------:|:-----------:|:-------:|:-----------:|:--------------:|:-----------:|:-------:|:-----------:|:--------------:|:-----------:|:-------:|:-----------:|:--------------:|:-----------:|:-------:|:-----------:|:--------------:|:-----------:|:-------:|:-----------:|:--------------:|:-----------:|:-------:|:-----------:|:--------------:|:-----------:|:-------:|:-----------:|:--------------:|:-----------:|:-------:|:-----------:|:--------------:|:-----------:|:-------:|:-----------:|:--------------:|:-----------:|:-------:|:-----------:|:--------------:|:-----------:|:-------:|:-----------:|:--------------:|:-----------:|:-------:|:-----------:|:--------------:|:-----------:|:-------:|:-----------:|:--------------:|:-----------:|:-------:|:-----------:|:--------------:|:-----------:|:-------:|:-----------:|:--------------:|:-----------:|:-------:|:-----------:|:--------------:|:-----------:|:-------:|:-----------:|:--------------:|:-----------:|:-------:|:-----------:|:--------------:|:-----------:|:-------:|:-----------:|:-----------------:|:--------------:|:----------:|:----------------:|
| 0.5327        | 1.0   | 1455  | 0.4482          | 0.0            | 0.0         | 0.0     | 25          | 0.0968         | 0.0667      | 0.0789  | 45          | 0.5197         | 0.5872      | 0.5514  | 1233        | 0.0            | 0.0         | 0.0     | 9           | 0.0            | 0.0         | 0.0     | 22          | 0.4209         | 0.3946      | 0.4073  | 991         | 0.3256         | 0.3182      | 0.3218  | 44          | 0.6398         | 0.6032      | 0.6210  | 2568        | 0.5179         | 0.5434      | 0.5304  | 1487        | 0.4511         | 0.6105      | 0.5189  | 552         | 0.3902         | 0.2783      | 0.3249  | 115         | 0.4814         | 0.4704      | 0.4758  | 742         | 0.0            | 0.0         | 0.0     | 20          | 0.0            | 0.0         | 0.0     | 37          | 0.0            | 0.0         | 0.0     | 15          | 0.6038         | 0.7293      | 0.6606  | 351         | 0.6112         | 0.7266      | 0.6639  | 2187        | 0.0            | 0.0         | 0.0     | 28          | 0.4980         | 0.4114      | 0.4505  | 598         | 0.0            | 0.0         | 0.0     | 40          | 0.6384         | 0.7573      | 0.6928  | 478         | 0.5538            | 0.5748         | 0.5641     | 0.8574           |
| 0.3735        | 2.0   | 2910  | 0.4071          | 0.44           | 0.44        | 0.44    | 25          | 0.125          | 0.0667      | 0.0870  | 45          | 0.5824         | 0.6594      | 0.6185  | 1233        | 0.0            | 0.0         | 0.0     | 9           | 0.0            | 0.0         | 0.0     | 22          | 0.4991         | 0.2714      | 0.3516  | 991         | 0.3239         | 0.5227      | 0.4     | 44          | 0.6179         | 0.6846      | 0.6495  | 2568        | 0.6069         | 0.5286      | 0.5651  | 1487        | 0.5031         | 0.5960      | 0.5456  | 552         | 0.4779         | 0.4696      | 0.4737  | 115         | 0.5329         | 0.4906      | 0.5109  | 742         | 0.0            | 0.0         | 0.0     | 20          | 0.0862         | 0.1351      | 0.1053  | 37          | 0.0833         | 0.0667      | 0.0741  | 15          | 0.7054         | 0.7094      | 0.7074  | 351         | 0.6601         | 0.7380      | 0.6969  | 2187        | 0.5            | 0.0714      | 0.125   | 28          | 0.5016         | 0.5217      | 0.5115  | 598         | 0.3333         | 0.025       | 0.0465  | 40          | 0.6507         | 0.7950      | 0.7156  | 478         | 0.5946            | 0.6019         | 0.5982     | 0.8692           |
| 0.2678        | 3.0   | 4365  | 0.4086          | 0.2727         | 0.84        | 0.4118  | 25          | 0.2603         | 0.4222      | 0.3220  | 45          | 0.5859         | 0.6610      | 0.6212  | 1233        | 0.0            | 0.0         | 0.0     | 9           | 1.0            | 0.0455      | 0.0870  | 22          | 0.4805         | 0.4480      | 0.4637  | 991         | 0.45           | 0.4091      | 0.4286  | 44          | 0.6727         | 0.6698      | 0.6712  | 2568        | 0.5692         | 0.6059      | 0.5870  | 1487        | 0.5070         | 0.5924      | 0.5464  | 552         | 0.5259         | 0.6174      | 0.568   | 115         | 0.5164         | 0.5526      | 0.5339  | 742         | 0.5            | 0.2         | 0.2857  | 20          | 0.1545         | 0.4595      | 0.2313  | 37          | 0.1034         | 0.2         | 0.1364  | 15          | 0.6896         | 0.7151      | 0.7021  | 351         | 0.6897         | 0.7389      | 0.7135  | 2187        | 0.6364         | 0.25        | 0.3590  | 28          | 0.5095         | 0.5853      | 0.5447  | 598         | 0.5            | 0.05        | 0.0909  | 40          | 0.7510         | 0.7950      | 0.7724  | 478         | 0.6006            | 0.6367         | 0.6181     | 0.8737           |
| 0.1855        | 4.0   | 5820  | 0.4385          | 0.5            | 0.72        | 0.5902  | 25          | 0.3667         | 0.2444      | 0.2933  | 45          | 0.6192         | 0.6594      | 0.6386  | 1233        | 0.0            | 0.0         | 0.0     | 9           | 0.7            | 0.3182      | 0.4375  | 22          | 0.4361         | 0.5267      | 0.4771  | 991         | 0.46           | 0.5227      | 0.4894  | 44          | 0.6570         | 0.7114      | 0.6831  | 2568        | 0.5476         | 0.6147      | 0.5792  | 1487        | 0.5079         | 0.6377      | 0.5655  | 552         | 0.5333         | 0.6261      | 0.5760  | 115         | 0.4989         | 0.6065      | 0.5474  | 742         | 0.4            | 0.2         | 0.2667  | 20          | 0.25           | 0.0811      | 0.1224  | 37          | 0.05           | 0.0667      | 0.0571  | 15          | 0.7151         | 0.7151      | 0.7151  | 351         | 0.7116         | 0.7343      | 0.7228  | 2187        | 0.6190         | 0.4643      | 0.5306  | 28          | 0.5171         | 0.5803      | 0.5469  | 598         | 0.4286         | 0.15        | 0.2222  | 40          | 0.7237         | 0.8054      | 0.7624  | 478         | 0.6002            | 0.6581         | 0.6278     | 0.8766           |
| 0.1277        | 5.0   | 7275  | 0.4812          | 0.5769         | 0.6         | 0.5882  | 25          | 0.6875         | 0.4889      | 0.5714  | 45          | 0.6488         | 0.6667      | 0.6576  | 1233        | 0.5            | 0.1111      | 0.1818  | 9           | 1.0            | 0.2727      | 0.4286  | 22          | 0.5162         | 0.4813      | 0.4982  | 991         | 0.5610         | 0.5227      | 0.5412  | 44          | 0.6924         | 0.6943      | 0.6934  | 2568        | 0.5884         | 0.6019      | 0.5951  | 1487        | 0.5242         | 0.6286      | 0.5717  | 552         | 0.5982         | 0.5826      | 0.5903  | 115         | 0.5557         | 0.5714      | 0.5635  | 742         | 0.3158         | 0.3         | 0.3077  | 20          | 0.1795         | 0.1892      | 0.1842  | 37          | 0.0455         | 0.0667      | 0.0541  | 15          | 0.6430         | 0.7493      | 0.6921  | 351         | 0.7132         | 0.7549      | 0.7335  | 2187        | 0.5217         | 0.4286      | 0.4706  | 28          | 0.5145         | 0.5334      | 0.5238  | 598         | 0.5            | 0.225       | 0.3103  | 40          | 0.7233         | 0.7929      | 0.7565  | 478         | 0.6316            | 0.6498         | 0.6406     | 0.8820           |
| 0.0861        | 6.0   | 8730  | 0.5200          | 0.9091         | 0.4         | 0.5556  | 25          | 0.5333         | 0.5333      | 0.5333  | 45          | 0.6353         | 0.6626      | 0.6487  | 1233        | 0.4286         | 0.3333      | 0.375   | 9           | 0.5882         | 0.4545      | 0.5128  | 22          | 0.4613         | 0.5106      | 0.4847  | 991         | 0.5263         | 0.4545      | 0.4878  | 44          | 0.6738         | 0.7079      | 0.6905  | 2568        | 0.5759         | 0.6254      | 0.5996  | 1487        | 0.5297         | 0.6467      | 0.5824  | 552         | 0.568          | 0.6174      | 0.5917  | 115         | 0.5550         | 0.6051      | 0.5790  | 742         | 0.4118         | 0.35        | 0.3784  | 20          | 0.2333         | 0.1892      | 0.2090  | 37          | 0.1667         | 0.1333      | 0.1481  | 15          | 0.725          | 0.7436      | 0.7342  | 351         | 0.7045         | 0.7631      | 0.7327  | 2187        | 0.8462         | 0.3929      | 0.5366  | 28          | 0.5496         | 0.5836      | 0.5661  | 598         | 0.4167         | 0.25        | 0.3125  | 40          | 0.7247         | 0.7929      | 0.7572  | 478         | 0.6215            | 0.6654         | 0.6427     | 0.8819           |
| 0.0593        | 7.0   | 10185 | 0.5801          | 0.5789         | 0.44        | 0.5     | 25          | 0.6111         | 0.4889      | 0.5432  | 45          | 0.6546         | 0.6764      | 0.6653  | 1233        | 0.3333         | 0.3333      | 0.3333  | 9           | 0.6667         | 0.4545      | 0.5405  | 22          | 0.5133         | 0.5066      | 0.5099  | 991         | 0.7            | 0.4773      | 0.5676  | 44          | 0.6855         | 0.7079      | 0.6966  | 2568        | 0.5766         | 0.6402      | 0.6068  | 1487        | 0.5201         | 0.6322      | 0.5707  | 552         | 0.568          | 0.6174      | 0.5917  | 115         | 0.6156         | 0.5526      | 0.5824  | 742         | 0.3684         | 0.35        | 0.3590  | 20          | 0.1628         | 0.1892      | 0.1750  | 37          | 0.2            | 0.2         | 0.2000  | 15          | 0.7406         | 0.7322      | 0.7364  | 351         | 0.7103         | 0.7769      | 0.7421  | 2187        | 0.6818         | 0.5357      | 0.6     | 28          | 0.5503         | 0.5853      | 0.5673  | 598         | 0.4583         | 0.275       | 0.3437  | 40          | 0.7505         | 0.7678      | 0.7590  | 478         | 0.6372            | 0.6662         | 0.6514     | 0.8839           |
| 0.0422        | 8.0   | 11640 | 0.6200          | 0.4828         | 0.56        | 0.5185  | 25          | 0.5909         | 0.5778      | 0.5843  | 45          | 0.6380         | 0.6991      | 0.6672  | 1233        | 0.4286         | 0.3333      | 0.375   | 9           | 0.6429         | 0.4091      | 0.5000  | 22          | 0.4874         | 0.5257      | 0.5058  | 991         | 0.5946         | 0.5         | 0.5432  | 44          | 0.6631         | 0.7235      | 0.6920  | 2568        | 0.5733         | 0.6261      | 0.5985  | 1487        | 0.5195         | 0.5797      | 0.5479  | 552         | 0.5726         | 0.6174      | 0.5941  | 115         | 0.5981         | 0.5876      | 0.5928  | 742         | 0.375          | 0.3         | 0.3333  | 20          | 0.2353         | 0.2162      | 0.2254  | 37          | 0.1739         | 0.2667      | 0.2105  | 15          | 0.6875         | 0.7208      | 0.7038  | 351         | 0.7364         | 0.7549      | 0.7455  | 2187        | 0.5385         | 0.5         | 0.5185  | 28          | 0.5481         | 0.5903      | 0.5684  | 598         | 0.4333         | 0.325       | 0.3714  | 40          | 0.7376         | 0.7762      | 0.7564  | 478         | 0.6281            | 0.6685         | 0.6477     | 0.8825           |
| 0.0304        | 9.0   | 13095 | 0.6571          | 0.6667         | 0.48        | 0.5581  | 25          | 0.7143         | 0.5556      | 0.6250  | 45          | 0.6468         | 0.6951      | 0.6701  | 1233        | 0.3333         | 0.1111      | 0.1667  | 9           | 0.6471         | 0.5         | 0.5641  | 22          | 0.4770         | 0.5449      | 0.5087  | 991         | 0.575          | 0.5227      | 0.5476  | 44          | 0.6774         | 0.7196      | 0.6979  | 2568        | 0.5786         | 0.6214      | 0.5992  | 1487        | 0.5396         | 0.5924      | 0.5648  | 552         | 0.6            | 0.6261      | 0.6128  | 115         | 0.5986         | 0.5768      | 0.5875  | 742         | 0.4615         | 0.3         | 0.3636  | 20          | 0.1795         | 0.1892      | 0.1842  | 37          | 0.1            | 0.0667      | 0.08    | 15          | 0.7127         | 0.7208      | 0.7167  | 351         | 0.7271         | 0.7590      | 0.7427  | 2187        | 0.4            | 0.5         | 0.4444  | 28          | 0.5550         | 0.5652      | 0.5601  | 598         | 0.4231         | 0.275       | 0.3333  | 40          | 0.7525         | 0.7950      | 0.7731  | 478         | 0.6337            | 0.6678         | 0.6503     | 0.8839           |
| 0.0219        | 10.0  | 14550 | 0.6765          | 0.6667         | 0.48        | 0.5581  | 25          | 0.6486         | 0.5333      | 0.5854  | 45          | 0.6560         | 0.6991      | 0.6769  | 1233        | 0.6            | 0.3333      | 0.4286  | 9           | 0.6111         | 0.5         | 0.55    | 22          | 0.5205         | 0.5388      | 0.5295  | 991         | 0.575          | 0.5227      | 0.5476  | 44          | 0.6850         | 0.7095      | 0.6970  | 2568        | 0.5744         | 0.6409      | 0.6058  | 1487        | 0.5197         | 0.5725      | 0.5448  | 552         | 0.5785         | 0.6087      | 0.5932  | 115         | 0.588          | 0.5943      | 0.5912  | 742         | 0.4667         | 0.35        | 0.4     | 20          | 0.2            | 0.1892      | 0.1944  | 37          | 0.1429         | 0.2         | 0.1667  | 15          | 0.6986         | 0.7265      | 0.7123  | 351         | 0.7322         | 0.7590      | 0.7454  | 2187        | 0.4815         | 0.4643      | 0.4727  | 28          | 0.5545         | 0.5786      | 0.5663  | 598         | 0.4            | 0.3         | 0.3429  | 40          | 0.7470         | 0.7782      | 0.7623  | 478         | 0.6382            | 0.6685         | 0.6530     | 0.8851           |


### Framework versions

- Transformers 4.48.2
- Pytorch 2.6.0+cu124
- Datasets 3.2.0
- Tokenizers 0.21.1
