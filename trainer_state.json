{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.710188228264117,
  "eval_steps": 500,
  "global_step": 32500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.14938751120406335,
      "grad_norm": 2.448774576187134,
      "learning_rate": 4.9253062443979686e-05,
      "loss": 0.8793,
      "step": 500
    },
    {
      "epoch": 0.2987750224081267,
      "grad_norm": 2.510652542114258,
      "learning_rate": 4.850612488795937e-05,
      "loss": 0.5525,
      "step": 1000
    },
    {
      "epoch": 0.44816253361219,
      "grad_norm": 2.3369085788726807,
      "learning_rate": 4.775918733193905e-05,
      "loss": 0.4958,
      "step": 1500
    },
    {
      "epoch": 0.5975500448162534,
      "grad_norm": 2.7931995391845703,
      "learning_rate": 4.7012249775918735e-05,
      "loss": 0.4665,
      "step": 2000
    },
    {
      "epoch": 0.7469375560203168,
      "grad_norm": 3.0105459690093994,
      "learning_rate": 4.626531221989842e-05,
      "loss": 0.4597,
      "step": 2500
    },
    {
      "epoch": 0.89632506722438,
      "grad_norm": 1.7761173248291016,
      "learning_rate": 4.55183746638781e-05,
      "loss": 0.4349,
      "step": 3000
    },
    {
      "epoch": 1.0457125784284433,
      "grad_norm": 1.9104008674621582,
      "learning_rate": 4.4771437107857785e-05,
      "loss": 0.39,
      "step": 3500
    },
    {
      "epoch": 1.1951000896325068,
      "grad_norm": 3.5061662197113037,
      "learning_rate": 4.402449955183747e-05,
      "loss": 0.3392,
      "step": 4000
    },
    {
      "epoch": 1.34448760083657,
      "grad_norm": 3.7045559883117676,
      "learning_rate": 4.327756199581715e-05,
      "loss": 0.3245,
      "step": 4500
    },
    {
      "epoch": 1.4938751120406333,
      "grad_norm": 2.986313819885254,
      "learning_rate": 4.2530624439796834e-05,
      "loss": 0.3204,
      "step": 5000
    },
    {
      "epoch": 1.6432626232446967,
      "grad_norm": 3.7821261882781982,
      "learning_rate": 4.178368688377652e-05,
      "loss": 0.316,
      "step": 5500
    },
    {
      "epoch": 1.7926501344487602,
      "grad_norm": 3.73421573638916,
      "learning_rate": 4.10367493277562e-05,
      "loss": 0.3153,
      "step": 6000
    },
    {
      "epoch": 1.9420376456528234,
      "grad_norm": 3.1852619647979736,
      "learning_rate": 4.0289811771735884e-05,
      "loss": 0.3138,
      "step": 6500
    },
    {
      "epoch": 2.0914251568568867,
      "grad_norm": 2.0410287380218506,
      "learning_rate": 3.954287421571557e-05,
      "loss": 0.248,
      "step": 7000
    },
    {
      "epoch": 2.24081266806095,
      "grad_norm": 3.4860243797302246,
      "learning_rate": 3.879593665969525e-05,
      "loss": 0.2099,
      "step": 7500
    },
    {
      "epoch": 2.3902001792650136,
      "grad_norm": 4.948462963104248,
      "learning_rate": 3.804899910367494e-05,
      "loss": 0.2172,
      "step": 8000
    },
    {
      "epoch": 2.5395876904690766,
      "grad_norm": 3.971313238143921,
      "learning_rate": 3.730206154765462e-05,
      "loss": 0.2154,
      "step": 8500
    },
    {
      "epoch": 2.68897520167314,
      "grad_norm": 3.2836191654205322,
      "learning_rate": 3.65551239916343e-05,
      "loss": 0.2208,
      "step": 9000
    },
    {
      "epoch": 2.8383627128772035,
      "grad_norm": 3.1039862632751465,
      "learning_rate": 3.580818643561398e-05,
      "loss": 0.2177,
      "step": 9500
    },
    {
      "epoch": 2.9877502240812666,
      "grad_norm": 3.924931287765503,
      "learning_rate": 3.5061248879593667e-05,
      "loss": 0.2221,
      "step": 10000
    },
    {
      "epoch": 3.13713773528533,
      "grad_norm": 3.015170097351074,
      "learning_rate": 3.431431132357335e-05,
      "loss": 0.1432,
      "step": 10500
    },
    {
      "epoch": 3.2865252464893935,
      "grad_norm": 4.541976451873779,
      "learning_rate": 3.356737376755303e-05,
      "loss": 0.1376,
      "step": 11000
    },
    {
      "epoch": 3.435912757693457,
      "grad_norm": 3.955906391143799,
      "learning_rate": 3.2820436211532716e-05,
      "loss": 0.1385,
      "step": 11500
    },
    {
      "epoch": 3.5853002688975204,
      "grad_norm": 2.9657342433929443,
      "learning_rate": 3.20734986555124e-05,
      "loss": 0.1481,
      "step": 12000
    },
    {
      "epoch": 3.7346877801015834,
      "grad_norm": 4.766768932342529,
      "learning_rate": 3.132656109949208e-05,
      "loss": 0.1431,
      "step": 12500
    },
    {
      "epoch": 3.884075291305647,
      "grad_norm": 3.109879732131958,
      "learning_rate": 3.057962354347177e-05,
      "loss": 0.1479,
      "step": 13000
    },
    {
      "epoch": 4.03346280250971,
      "grad_norm": 3.2963707447052,
      "learning_rate": 2.9832685987451452e-05,
      "loss": 0.129,
      "step": 13500
    },
    {
      "epoch": 4.182850313713773,
      "grad_norm": 5.600860118865967,
      "learning_rate": 2.9085748431431132e-05,
      "loss": 0.0887,
      "step": 14000
    },
    {
      "epoch": 4.332237824917837,
      "grad_norm": 6.638391017913818,
      "learning_rate": 2.8338810875410815e-05,
      "loss": 0.0922,
      "step": 14500
    },
    {
      "epoch": 4.4816253361219,
      "grad_norm": 2.8345181941986084,
      "learning_rate": 2.75918733193905e-05,
      "loss": 0.0983,
      "step": 15000
    },
    {
      "epoch": 4.631012847325963,
      "grad_norm": 3.7209043502807617,
      "learning_rate": 2.6844935763370182e-05,
      "loss": 0.0961,
      "step": 15500
    },
    {
      "epoch": 4.780400358530027,
      "grad_norm": 6.16909122467041,
      "learning_rate": 2.6097998207349865e-05,
      "loss": 0.096,
      "step": 16000
    },
    {
      "epoch": 4.92978786973409,
      "grad_norm": 6.858531475067139,
      "learning_rate": 2.535106065132955e-05,
      "loss": 0.0969,
      "step": 16500
    },
    {
      "epoch": 5.079175380938153,
      "grad_norm": 5.49943733215332,
      "learning_rate": 2.4604123095309235e-05,
      "loss": 0.079,
      "step": 17000
    },
    {
      "epoch": 5.228562892142217,
      "grad_norm": 3.452274799346924,
      "learning_rate": 2.3857185539288918e-05,
      "loss": 0.0593,
      "step": 17500
    },
    {
      "epoch": 5.37795040334628,
      "grad_norm": 1.545617699623108,
      "learning_rate": 2.3110247983268598e-05,
      "loss": 0.0649,
      "step": 18000
    },
    {
      "epoch": 5.527337914550344,
      "grad_norm": 3.502764940261841,
      "learning_rate": 2.236331042724828e-05,
      "loss": 0.0647,
      "step": 18500
    },
    {
      "epoch": 5.676725425754407,
      "grad_norm": 1.927117943763733,
      "learning_rate": 2.1616372871227968e-05,
      "loss": 0.0636,
      "step": 19000
    },
    {
      "epoch": 5.82611293695847,
      "grad_norm": 2.770550012588501,
      "learning_rate": 2.086943531520765e-05,
      "loss": 0.0649,
      "step": 19500
    },
    {
      "epoch": 5.975500448162533,
      "grad_norm": 0.7983459830284119,
      "learning_rate": 2.0122497759187334e-05,
      "loss": 0.0648,
      "step": 20000
    },
    {
      "epoch": 6.124887959366597,
      "grad_norm": 3.39992618560791,
      "learning_rate": 1.9375560203167017e-05,
      "loss": 0.0461,
      "step": 20500
    },
    {
      "epoch": 6.27427547057066,
      "grad_norm": 1.5369161367416382,
      "learning_rate": 1.8628622647146697e-05,
      "loss": 0.0433,
      "step": 21000
    },
    {
      "epoch": 6.423662981774724,
      "grad_norm": 2.4660933017730713,
      "learning_rate": 1.7881685091126384e-05,
      "loss": 0.0412,
      "step": 21500
    },
    {
      "epoch": 6.573050492978787,
      "grad_norm": 2.9344022274017334,
      "learning_rate": 1.7134747535106067e-05,
      "loss": 0.0424,
      "step": 22000
    },
    {
      "epoch": 6.72243800418285,
      "grad_norm": 2.7929773330688477,
      "learning_rate": 1.638780997908575e-05,
      "loss": 0.0426,
      "step": 22500
    },
    {
      "epoch": 6.871825515386914,
      "grad_norm": 1.5888863801956177,
      "learning_rate": 1.5640872423065433e-05,
      "loss": 0.0425,
      "step": 23000
    },
    {
      "epoch": 7.021213026590977,
      "grad_norm": 0.4050617516040802,
      "learning_rate": 1.4893934867045115e-05,
      "loss": 0.0393,
      "step": 23500
    },
    {
      "epoch": 7.17060053779504,
      "grad_norm": 3.92383074760437,
      "learning_rate": 1.4146997311024798e-05,
      "loss": 0.0273,
      "step": 24000
    },
    {
      "epoch": 7.319988048999104,
      "grad_norm": 0.5246223211288452,
      "learning_rate": 1.3400059755004481e-05,
      "loss": 0.0269,
      "step": 24500
    },
    {
      "epoch": 7.469375560203167,
      "grad_norm": 0.6501342058181763,
      "learning_rate": 1.2653122198984166e-05,
      "loss": 0.0266,
      "step": 25000
    },
    {
      "epoch": 7.61876307140723,
      "grad_norm": 6.309214115142822,
      "learning_rate": 1.1906184642963848e-05,
      "loss": 0.0284,
      "step": 25500
    },
    {
      "epoch": 7.768150582611294,
      "grad_norm": 1.648352861404419,
      "learning_rate": 1.1159247086943533e-05,
      "loss": 0.0285,
      "step": 26000
    },
    {
      "epoch": 7.917538093815357,
      "grad_norm": 6.4706268310546875,
      "learning_rate": 1.0412309530923216e-05,
      "loss": 0.0289,
      "step": 26500
    },
    {
      "epoch": 8.06692560501942,
      "grad_norm": 1.180829405784607,
      "learning_rate": 9.665371974902897e-06,
      "loss": 0.0227,
      "step": 27000
    },
    {
      "epoch": 8.216313116223484,
      "grad_norm": 1.1264954805374146,
      "learning_rate": 8.918434418882582e-06,
      "loss": 0.018,
      "step": 27500
    },
    {
      "epoch": 8.365700627427547,
      "grad_norm": 4.364627361297607,
      "learning_rate": 8.171496862862265e-06,
      "loss": 0.0172,
      "step": 28000
    },
    {
      "epoch": 8.51508813863161,
      "grad_norm": 2.6958630084991455,
      "learning_rate": 7.424559306841948e-06,
      "loss": 0.0183,
      "step": 28500
    },
    {
      "epoch": 8.664475649835675,
      "grad_norm": 4.3405585289001465,
      "learning_rate": 6.677621750821632e-06,
      "loss": 0.018,
      "step": 29000
    },
    {
      "epoch": 8.813863161039738,
      "grad_norm": 0.6383194923400879,
      "learning_rate": 5.930684194801315e-06,
      "loss": 0.0173,
      "step": 29500
    },
    {
      "epoch": 8.9632506722438,
      "grad_norm": 1.5687007904052734,
      "learning_rate": 5.183746638780998e-06,
      "loss": 0.0171,
      "step": 30000
    },
    {
      "epoch": 9.112638183447864,
      "grad_norm": 3.1015589237213135,
      "learning_rate": 4.4368090827606815e-06,
      "loss": 0.0138,
      "step": 30500
    },
    {
      "epoch": 9.262025694651927,
      "grad_norm": 1.08747398853302,
      "learning_rate": 3.6898715267403647e-06,
      "loss": 0.0123,
      "step": 31000
    },
    {
      "epoch": 9.41141320585599,
      "grad_norm": 4.881885051727295,
      "learning_rate": 2.942933970720048e-06,
      "loss": 0.0116,
      "step": 31500
    },
    {
      "epoch": 9.560800717060054,
      "grad_norm": 0.5718547701835632,
      "learning_rate": 2.1959964146997315e-06,
      "loss": 0.012,
      "step": 32000
    },
    {
      "epoch": 9.710188228264117,
      "grad_norm": 2.652353286743164,
      "learning_rate": 1.4490588586794143e-06,
      "loss": 0.0122,
      "step": 32500
    }
  ],
  "logging_steps": 500,
  "max_steps": 33470,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8785668909708108.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
